{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad2821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference example\n",
    "from nequip.data import dataset_from_config\n",
    "from nequip.utils import Config\n",
    "#from nequip.utils.misc import get_default_device_name\n",
    "#from nequip.utils.config import _GLOBAL_ALL_ASKED_FOR_KEYS\n",
    "\n",
    "from nequip.model import model_from_config\n",
    "\n",
    "\n",
    "default_config = dict(\n",
    "    root=\"./\",\n",
    "    tensorboard=False,\n",
    "    wandb=False,\n",
    "    model_builders=[\n",
    "        \"SimpleIrrepsConfig\",\n",
    "        \"EnergyModel\",\n",
    "        \"PerSpeciesRescale\",\n",
    "        \"StressForceOutput\",\n",
    "        \"RescaleEnergyEtc\",\n",
    "    ],\n",
    "    dataset_statistics_stride=1,\n",
    "    device='cuda',\n",
    "    default_dtype=\"float64\",\n",
    "    model_dtype=\"float32\",\n",
    "    allow_tf32=True,\n",
    "    verbose=\"INFO\",\n",
    "    model_debug_mode=False,\n",
    "    equivariance_test=False,\n",
    "    grad_anomaly_mode=False,\n",
    "    gpu_oom_offload=False,\n",
    "    append=False,\n",
    "    warn_unused=False,\n",
    "    _jit_bailout_depth=2,  # avoid 20 iters of pain, see https://github.com/pytorch/pytorch/issues/52286\n",
    "    # Quote from eelison in PyTorch slack:\n",
    "    # https://pytorch.slack.com/archives/CDZD1FANA/p1644259272007529?thread_ts=1644064449.039479&cid=CDZD1FANA\n",
    "    # > Right now the default behavior is to specialize twice on static shapes and then on dynamic shapes.\n",
    "    # > To reduce warmup time you can do something like setFusionStrartegy({{FusionBehavior::DYNAMIC, 3}})\n",
    "    # > ... Although we would wouldn't really expect to recompile a dynamic shape fusion in a model,\n",
    "    # > provided broadcasting patterns remain fixed\n",
    "    # We default to DYNAMIC alone because the number of edges is always dynamic,\n",
    "    # even if the number of atoms is fixed:\n",
    "    _jit_fusion_strategy=[(\"DYNAMIC\", 3)],\n",
    "    # Due to what appear to be ongoing bugs with nvFuser, we default to NNC (fuser1) for now:\n",
    "    # TODO: still default to NNC on CPU regardless even if change this for GPU\n",
    "    # TODO: default for ROCm?\n",
    "    _jit_fuser=\"fuser1\",\n",
    ")\n",
    "\n",
    "# All default_config keys are valid / requested\n",
    "#_GLOBAL_ALL_ASKED_FOR_KEYS.update(default_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d80fac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicData(atom_types=[21, 1], cell=[3, 3], edge_cell_shift=[364, 3], edge_index=[2, 364], forces=[21, 3], pbc=[3], pos=[21, 3], total_energy=[1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_file('./configs/example.yaml', defaults=default_config)\n",
    "    \n",
    "\n",
    "dataset = dataset_from_config(config, prefix=\"dataset\")\n",
    "\n",
    "validation_dataset = None\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c25eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:* Initialize Output\n",
      "  ...generate file name results/aspirin/example/log\n",
      "  ...open log file results/aspirin/example/log\n",
      "  ...generate file name results/aspirin/example/metrics_epoch.csv\n",
      "  ...open log file results/aspirin/example/metrics_epoch.csv\n",
      "  ...generate file name results/aspirin/example/metrics_initialization.csv\n",
      "  ...open log file results/aspirin/example/metrics_initialization.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_train.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_train.csv\n",
      "  ...generate file name results/aspirin/example/metrics_batch_val.csv\n",
      "  ...open log file results/aspirin/example/metrics_batch_val.csv\n",
      "  ...generate file name results/aspirin/example/best_model.pth\n",
      "  ...generate file name results/aspirin/example/last_model.pth\n",
      "  ...generate file name results/aspirin/example/trainer.pth\n",
      "  ...generate file name results/aspirin/example/config.yaml\n",
      "Torch device: cuda\n",
      "instantiate Loss\n",
      "...Loss_param = dict(\n",
      "...   optional_args = {'coeff_schedule': 'constant'},\n",
      "...   positional_args = {'coeffs': {'forces': 1.0, 'total_energy': [1.0, 'PerAtomMSELoss']}})\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing forces 1.0\n",
      " parsing 1.0 MSELoss\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      " parsing total_energy [1.0, 'PerAtomMSELoss']\n",
      " parsing 1.0 PerAtomMSELoss\n",
      "create loss instance <class 'nequip.train._loss.PerAtomLoss'>\n",
      "instantiate MSELoss\n",
      "...MSELoss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "Building Allegro model...\n",
      "instantiate OneHotAtomEncoding\n",
      "        all_args :                                           num_types\n",
      "...OneHotAtomEncoding_param = dict(\n",
      "...   optional_args = {'set_features': True, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': None})\n",
      "instantiate RadialBasisEdgeEncoding\n",
      "        all_args :                                  basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :            basis_kwargs.original_basis_kwargs.r_max <-                                              r_max\n",
      "        all_args :        basis_kwargs.original_basis_kwargs.trainable <-                              BesselBasis_trainable\n",
      "        all_args :                                 cutoff_kwargs.r_max <-                                              r_max\n",
      "        all_args :                                     cutoff_kwargs.p <-                                 PolynomialCutoff_p\n",
      "   optional_args :                                               basis\n",
      "   optional_args :                                           out_field\n",
      "...RadialBasisEdgeEncoding_param = dict(\n",
      "...   optional_args = {'basis': <class 'allegro.nn._norm_basis.NormalizedBasis'>, 'cutoff': <class 'nequip.nn.cutoffs.PolynomialCutoff'>, 'basis_kwargs': {'r_min': 0.0, 'original_basis': <class 'nequip.nn.radial_basis.BesselBasis'>, 'original_basis_kwargs': {'num_basis': 8, 'trainable': True, 'r_max': 6.0}, 'n': 4000, 'norm_basis_mean_shift': True, 'r_max': 6.0}, 'cutoff_kwargs': {'p': 6, 'r_max': 6.0}, 'out_field': 'edge_embedding'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e}})\n",
      "instantiate SphericalHarmonicEdgeAttrs\n",
      "        all_args :                                      irreps_edge_sh\n",
      "...SphericalHarmonicEdgeAttrs_param = dict(\n",
      "...   optional_args = {'edge_sh_normalization': 'component', 'edge_sh_normalize': True, 'out_field': 'edge_attrs', 'irreps_edge_sh': '1x0e+1x1o+1x2e'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e}})\n",
      "instantiate Allegro_Module\n",
      "        all_args :                                               r_max\n",
      "        all_args :                                  PolynomialCutoff_p\n",
      "        all_args :                                          num_layers\n",
      "        all_args :                                       latent_resnet\n",
      "        all_args :                                           num_types\n",
      "        all_args :                              env_embed_multiplicity\n",
      "        all_args :                                   avg_num_neighbors\n",
      "        all_args :                                  embed_initial_edge\n",
      "        all_args :                           nonscalars_include_parity\n",
      "        all_args :        two_body_latent_kwargs.mlp_latent_dimensions <-              two_body_latent_mlp_latent_dimensions\n",
      "        all_args :             two_body_latent_kwargs.mlp_nonlinearity <-                   two_body_latent_mlp_nonlinearity\n",
      "        all_args :           two_body_latent_kwargs.mlp_initialization <-                 two_body_latent_mlp_initialization\n",
      "        all_args :              env_embed_kwargs.mlp_latent_dimensions <-                    env_embed_mlp_latent_dimensions\n",
      "        all_args :                   env_embed_kwargs.mlp_nonlinearity <-                         env_embed_mlp_nonlinearity\n",
      "        all_args :                 env_embed_kwargs.mlp_initialization <-                       env_embed_mlp_initialization\n",
      "        all_args :                 latent_kwargs.mlp_latent_dimensions <-                       latent_mlp_latent_dimensions\n",
      "        all_args :                      latent_kwargs.mlp_nonlinearity <-                            latent_mlp_nonlinearity\n",
      "        all_args :                    latent_kwargs.mlp_initialization <-                          latent_mlp_initialization\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                edge_invariant_field\n",
      "   optional_args :                                node_invariant_field\n",
      "...Allegro_Module_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'r_start_cos_ratio': 0.8, 'PolynomialCutoff_p': 6, 'per_layer_cutoffs': None, 'cutoff_type': 'polynomial', 'field': 'edge_attrs', 'edge_invariant_field': 'edge_embedding', 'node_invariant_field': 'node_attrs', 'env_embed_multiplicity': 64, 'embed_initial_edge': True, 'linear_after_env_embed': False, 'nonscalars_include_parity': True, 'two_body_latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'two_body_latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [128, 256, 512, 1024]}, 'env_embed': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'env_embed_kwargs': {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': []}, 'latent': <class 'allegro.nn._fc.ScalarMLPFunction'>, 'latent_kwargs': {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'mlp_latent_dimensions': [1024, 1024, 1024]}, 'latent_resnet': True, 'latent_resnet_update_ratios': None, 'latent_resnet_update_ratios_learnable': False, 'latent_out_field': 'edge_features', 'pad_to_alignment': 1, 'sparse_mode': None, 'r_max': 6.0, 'num_layers': 2, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e}})\n",
      "/Users/temporary/Documents/GitHub/pytorch-intel-mps/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n",
      "instantiate ScalarMLP\n",
      "        all_args :                               mlp_latent_dimensions <-                     edge_eng_mlp_latent_dimensions\n",
      "        all_args :                                    mlp_nonlinearity <-                          edge_eng_mlp_nonlinearity\n",
      "        all_args :                                  mlp_initialization <-                        edge_eng_mlp_initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   optional_args :                                               field\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                mlp_output_dimension\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': None, 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_energy', 'mlp_latent_dimensions': [128], 'mlp_output_dimension': 1},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e}})\n",
      "instantiate ScalarMLP\n",
      "   optional_args :                               mlp_latent_dimensions\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                mlp_output_dimension\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_spin', 'mlp_latent_dimensions': [], 'mlp_output_dimension': 1},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e}})\n",
      "instantiate ScalarMLP\n",
      "   optional_args :                               mlp_latent_dimensions\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                mlp_output_dimension\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_J', 'mlp_latent_dimensions': [], 'mlp_output_dimension': 1},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'edge_spin': 1x0e}})\n",
      "instantiate EdgewiseEnergySum\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                   avg_num_neighbors\n",
      "...EdgewiseEnergySum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'normalize_edge_energy_sum': True, 'per_edge_species_scale': False, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'edge_spin': 1x0e, 'edge_J': 1x0e}})\n",
      "instantiate EdgewiseSpinSum\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                   avg_num_neighbors\n",
      "...EdgewiseSpinSum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 17.211328506469727, 'normalize_edge_spin_sum': True, 'per_edge_species_scale': False, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'edge_spin': 1x0e, 'edge_J': 1x0e, 'atomic_energy': 1x0e}})\n",
      "instantiate AtomwiseReduce\n",
      "   optional_args :                                              reduce\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                           out_field\n",
      "...AtomwiseReduce_param = dict(\n",
      "...   optional_args = {'out_field': 'total_energy', 'reduce': 'sum', 'avg_num_atoms': None, 'field': 'atomic_energy'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'edge_spin': 1x0e, 'edge_J': 1x0e, 'atomic_energy': 1x0e, 'atomic_spin': 1x0e}})\n",
      "Replace string dataset_forces_rms to 31.252248764038086\n",
      "Replace string dataset_per_atom_total_energy_mean to -19318.35546875\n",
      "Atomic outputs are scaled by: [H, C, O: 31.252249], shifted by [H, C, O: -19318.355469].\n",
      "instantiate PerSpeciesScaleShift\n",
      "        all_args :                                          type_names\n",
      "        all_args :                                           num_types\n",
      "        all_args :                                       default_dtype\n",
      "   optional_args :                                               field\n",
      "   optional_args :                                              scales\n",
      "   optional_args :                          arguments_in_dataset_units\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                              shifts\n",
      "...PerSpeciesScaleShift_param = dict(\n",
      "...   optional_args = {'out_field': 'atomic_energy', 'scales_trainable': False, 'shifts_trainable': False, 'default_dtype': 'float32', 'num_types': 3, 'type_names': ['H', 'C', 'O'], 'field': 'atomic_energy', 'shifts': tensor(-19318.3555), 'scales': tensor(31.2522), 'arguments_in_dataset_units': True},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'node_attrs': 3x0e, 'node_features': 3x0e, 'edge_embedding': 8x0e, 'edge_cutoff': 1x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 1024x0e, 'edge_energy': 1x0e, 'edge_spin': 1x0e, 'edge_J': 1x0e, 'atomic_energy': 1x0e, 'atomic_spin': 1x0e}})\n",
      "Replace string dataset_forces_rms to 31.252248764038086\n",
      "Initially outputs are globally scaled by: 31.252248764038086, total_energy are globally shifted by None.\n",
      "PerSpeciesScaleShift's arguments were in dataset units; rescaling:\n",
      "  Original scales: [H: 31.252249, C: 31.252249, O: 31.252249] shifts: [H: -19318.355469, C: -19318.355469, O: -19318.355469]\n",
      "  New scales: [H: 1.000000, C: 1.000000, O: 1.000000] shifts: [H: -618.142883, C: -618.142883, O: -618.142883]\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "from nequip.train.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=None, **Config.as_dict(config))\n",
    "\n",
    "# what is this\n",
    "# to update wandb data?\n",
    "config.update(trainer.params)\n",
    "\n",
    "# = Train/test split =\n",
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "# = Build model =\n",
    "final_model = model_from_config(\n",
    "    config=config, initialize=True, dataset=trainer.dataset_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc85d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from allegro import with_edge_spin_length\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data0 = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "data0['node_spin'] = torch.randn_like(data0['pos'])\n",
    "\n",
    "data1 = with_edge_spin_length(data0, with_distance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b553908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['node_spin_length'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea3507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b770a1a1-4f3b-4b96-9613-abecc3ae4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "data_new = final_model(AtomicData.to_AtomicDataDict(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3498836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_J'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcc77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10] + []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cce5ea4-01a4-4b6c-93db-5fb67d033c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_spin'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3570a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['atomic_spin'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adcee4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['atomic_energy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e90a214-7e5a-4e20-b143-7626462fa19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44252c37-418f-414f-b9d1-3d882160dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['edge_vectors'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61479ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of weights: 8152968\n",
      "Number of trainable weights: 8152968\n",
      "instantiate Adam\n",
      "...Adam_param = dict(\n",
      "...   optional_args = {'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None},\n",
      "...   positional_args = {'params': <generator object Module.parameters at 0x7b01698af6d0>, 'lr': 0.001})\n",
      "instantiate ReduceLROnPlateau\n",
      "        all_args :                                              factor <-                                lr_scheduler_factor\n",
      "        all_args :                                            patience <-                              lr_scheduler_patience\n",
      "...ReduceLROnPlateau_param = dict(\n",
      "...   optional_args = {'mode': 'min', 'factor': 0.5, 'patience': 50, 'threshold': 0.0001, 'threshold_mode': 'rel', 'cooldown': 0, 'min_lr': 0, 'eps': 1e-08, 'verbose': 'deprecated'},\n",
      "...   positional_args = {'optimizer': Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")})\n",
      "get args for EarlyStopping\n",
      "        all_args :                                        upper_bounds <-                        early_stopping_upper_bounds\n",
      "        all_args :                                           patiences <-                           early_stopping_patiences\n",
      "        all_args :                                        lower_bounds <-                        early_stopping_lower_bounds\n",
      "...EarlyStopping_param = dict(\n",
      "...   optional_args = {'lower_bounds': {'LR': 1e-05}, 'upper_bounds': {'cumulative_wall': 604800.0}, 'patiences': {'validation_loss': 100}, 'delta': {}, 'cumulative_delta': False},\n",
      "...   positional_args = {})\n",
      "! Starting training ...\n",
      "Saved trainer to results/aspirin/example/trainer.pth\n",
      "Saved last model to to results/aspirin/example/last_model.pth\n",
      "instantiate Metrics\n",
      "...Metrics_param = dict(\n",
      "...   optional_args = {},\n",
      "...   positional_args = {'components': [('forces', 'mae', {'PerSpecies': False}), ('forces', 'rmse', {'PerSpecies': False}), ('total_energy', 'mae', {'PerSpecies': False}), ('total_energy', 'rmse', {'PerSpecies': False})]})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "\n",
      "validation\n",
      "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae       e_rmse\n",
      "      0    10         1.88          1.5        0.383         27.8         38.2          406          406\n",
      "\n",
      "\n",
      "  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae       e_rmse\n",
      "! Initial Validation          0    5.638    0.001         1.47        0.379         1.84         28.5         37.8          404          404\n",
      "Wall time: 5.6391065130000015\n",
      "! Best model        0    1.845\n",
      "Saved trainer to results/aspirin/example/trainer.pth\n",
      "Saved last model to to results/aspirin/example/last_model.pth\n",
      "\n",
      "training\n",
      "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae       e_rmse\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:784\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_init_callback()\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_cond:\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_of_epoch_save()\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:919\u001b[0m, in \u001b[0;36mTrainer.epoch_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mibatch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVALIDATION\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_of_batch_log(batch_type\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_of_batch_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:826\u001b[0m, in \u001b[0;36mTrainer.batch_step\u001b[0;34m(self, data, validation)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# see https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#use-parameter-grad-none-instead-of-model-zero-grad-or-optimizer-zero-grad\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 826\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# See https://stackoverflow.com/a/56069467\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Has to happen after .backward() so there are grads to clip\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_gradient_norm \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a4fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3\n",
    "\n",
    "l_max = 2\n",
    "\n",
    "irreps_edge_sh = repr(\n",
    "            o3.Irreps.spherical_harmonics(\n",
    "                l_max, p=(-1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4bb8134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1x0e+1x1o+1x2e'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_edge_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a9dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "data = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "\n",
    "\n",
    "\n",
    "# edge length embedding\n",
    "torch.manual_seed(32)\n",
    "\n",
    "num_basis = 8\n",
    "r_max = 5\n",
    "\n",
    "\n",
    "data_my = {key: torch.clone(data[key]) for key in data}\n",
    "data_my = AtomicDataDict.with_edge_vectors(data_my, with_lengths=True)\n",
    "\n",
    "edge_length = data_my['edge_lengths']\n",
    "\n",
    "bessel_weights = (torch.linspace(start=1.0, end=num_basis, steps=num_basis) * math.pi)\n",
    "bessel_weights = nn.Parameter(bessel_weights)\n",
    "\n",
    "edge_length_embedding = 2/r_max*torch.sin(bessel_weights * edge_length.unsqueeze(-1) / r_max)/edge_length.unsqueeze(-1)\n",
    "\n",
    "# cutoff\n",
    "factor = 1/r_max\n",
    "p = 6\n",
    "    \n",
    "x = edge_length * factor\n",
    "\n",
    "cutoff = 1.0\n",
    "cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "cutoff *= (x < 1.0)\n",
    "\n",
    "cutoff = cutoff.unsqueeze(-1)\n",
    "\n",
    "data_my['edge_embedding'] = edge_length_embedding * cutoff\n",
    "\n",
    "# types embedding\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "edge_ind = data_my['edge_index']\n",
    "\n",
    "types_embed = one_hot(dataset[0]['atom_types'], num_classes)\n",
    "types_src = types_embed[edge_ind[0]].squeeze(1)\n",
    "types_dst = types_embed[edge_ind[1]].squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# latent vector\n",
    "latent_vector = torch.concatenate([types_src, types_dst, edge_length_embedding], dim = 1)\n",
    "\n",
    "# MLP\n",
    "invariant_layers = 2\n",
    "invariant_neurons = 64\n",
    "out_neurons = 32\n",
    "\n",
    "fc = FullyConnectedNet(\n",
    "    [latent_vector.shape[1]]\n",
    "    + invariant_layers * [invariant_neurons]\n",
    "    + [out_neurons],\n",
    "    torch.nn.functional.silu)\n",
    "\n",
    "latent_vector_out = fc(latent_vector)\n",
    "\n",
    "\n",
    "data_my['scalar'] = latent_vector_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c708419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 14])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89c32180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vector_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018f85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nequip.nn import AtomwiseLinear\n",
    "from e3nn.o3 import Irreps\n",
    "\n",
    "\n",
    "#data2_my = {key: torch.clone(data_my[key]) for key in data_my}\n",
    "\n",
    "linear1 = o3.Linear('32x0e', '32x0e')\n",
    "\n",
    "weight1 = linear1(latent_vector_out)\n",
    "weight1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae20a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "l_max = 2\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(2)\n",
    "\n",
    "data2_my = {key: torch.clone(data_my[key]) for key in data_my}\n",
    "data2_my = AtomicDataDict.with_edge_vectors(data2_my, with_lengths=False)\n",
    "\n",
    "\n",
    "harm_gen = o3.SphericalHarmonics(irreps_edge_sh, True, 'component')\n",
    "\n",
    "edge_vec = data_my['edge_vectors']\n",
    "\n",
    "harm_edge = harm_gen(edge_vec)\n",
    "harm_edge.shape\n",
    "\n",
    "\n",
    "data2_my['edge_features'] = harm_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f558c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.o3 import TensorProduct, Linear, FullyConnectedTensorProduct\n",
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "x = data2_my['edge_features']\n",
    "edge_src = data2_my['edge_index'][1]\n",
    "edge_dst = data2_my['edge_index'][0]\n",
    "\n",
    "\n",
    "term_1 = harm_edge\n",
    "edge_features = torch.einsum('ij,ib->ijb', weight1[edge_src], harm_edge[edge_src])\n",
    "\n",
    "# TODO: Check if it really right result\n",
    "edge_features = scatter(edge_features, edge_dst, dim=0, dim_size=len(x))\n",
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468f7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FullyConnectedTensorProduct(1x0e+1x1o+1x2e x 32x0e+32x1o+32x2e -> 32x0e+32x0o+32x1e+32x1o+32x2e+32x2o | 15360 paths | 15360 weights)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.o3 import TensorProduct, Linear, FullyConnectedTensorProduct\n",
    "\n",
    "hidden_layer_irrep = o3.Irreps(\"32x0e + 32x0o + 32x1e + 32x1o + 32x2e + 32x2o\")\n",
    "\n",
    "irreps_in = o3.Irreps(\"1x0e + 1x1o + 1x2e\")\n",
    "irreps_edge = o3.Irreps(\"32x0e + 32x1o + 32x2e\")\n",
    "\n",
    "\n",
    "irreps_mid = []\n",
    "instructions = []\n",
    "\n",
    "# instructions means stuff for multiplicities\n",
    "for i, (_, ir_in) in enumerate(irreps_in):\n",
    "    for j, (mul, ir_edge) in enumerate(irreps_edge):\n",
    "        for ir_out in ir_in * ir_edge:\n",
    "            if ir_out in hidden_layer_irrep:\n",
    "                k = len(irreps_mid)\n",
    "                irreps_mid.append((mul, ir_out))\n",
    "                instructions.append((i, j, k, \"uvu\", True))\n",
    "\n",
    "# We sort the output irreps of the tensor product so that we can simplify them\n",
    "# when they are provided to the second o3.Linear\n",
    "irreps_mid = o3.Irreps(irreps_mid)\n",
    "irreps_mid, p, _ = irreps_mid.sort()\n",
    "\n",
    "fctp = FullyConnectedTensorProduct(\n",
    "            irreps_in,\n",
    "            irreps_edge,\n",
    "            hidden_layer_irrep\n",
    "        )\n",
    "\n",
    "fctp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2b1d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e\n"
     ]
    }
   ],
   "source": [
    "irreps_scalar = o3.Irreps('32x0e')\n",
    "\n",
    "for el in irreps_scalar[0][1] * irreps_in[2][1]:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8c94ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+1x0e+1x1o+1x2e"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_scalar + irreps_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6217f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+32x1o+32x2e"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d4f3b26-2181-4352-a66b-96ff516ed8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from e3nn.o3 import FullTensorProduct\n",
    "\n",
    "#fctp(irrep_in, o3.Irreps('32x0e'))\n",
    "irreps_scalar = o3.Irreps('32x0e')\n",
    "\n",
    "\n",
    "fctp_simple = FullyConnectedTensorProduct(\n",
    "            irreps_scalar,\n",
    "            irreps_in,\n",
    "            irreps_edge\n",
    ")\n",
    "\n",
    "fctp_simple.visualize();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee46a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullyConnectedTensorProduct(32x0e x 1x0e+1x1o+1x2e -> 32x0e+32x1o+32x2e | 3072 paths | 3072 weights)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fctp_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a01e1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>, <Axes: >)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fctp.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62eeca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features_simple = fctp_simple(weight1, harm_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d54f9d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([364]), torch.Size([364, 288]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_dst.shape, edge_features_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ec3bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 288])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Check if it really right result\n",
    "edge_features_simple = scatter(edge_features_simple, edge_dst, dim=0, dim_size=len(x))\n",
    "edge_features_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57e4b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+32x1o+32x2e"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fctp_simple.irreps_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5fb994a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 288])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e79b4b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "288/9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6a43c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_edge.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aba2455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7318,  1.5868,  3.1454,  ...,  1.4503, -1.1855,  0.3548],\n",
       "        [ 0.1975,  1.8518,  4.1484,  ...,  0.5697, -0.9912, -0.1461],\n",
       "        [ 0.7615,  0.9864,  3.7604,  ...,  1.7781, -0.9809,  0.9555],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(edge_features.transpose(2, 1), -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c750875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4395,  -8.6668,  -7.1808,  ...,   0.7276,  -0.4207,   0.7423],\n",
       "        [ -4.9382, -10.0506,  -8.1547,  ...,   1.0427,   0.1516,   0.0430],\n",
       "        [ -3.9019,  -7.6113,  -6.3113,  ...,   0.3851,  -0.2934,   0.1124],\n",
       "        ...,\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       grad_fn=<ScatterAddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c485448",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fctp(harm_edge, edge_features_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d55c973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 576])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "788810b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 9, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harm_edge.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccac2e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 9, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edge_features.transpose(2, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eb25f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0717d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+32x0o+32x1e+32x1o+32x2e+32x2o"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_irrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81cc6e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 576])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8a797ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32x0e, 32x0o+32x1e+32x1o+32x2e+32x2o)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.nn import Extract\n",
    "\n",
    "irreps_scalar = []\n",
    "irreps_features = []\n",
    "for ir in hidden_layer_irrep:\n",
    "    if ir.ir[1] == 1 and ir.ir[0] == 0:\n",
    "        irreps_scalar.append(ir)\n",
    "    else:\n",
    "        irreps_features.append(ir)\n",
    "        \n",
    "irreps_scalar = o3.Irreps(irreps_scalar)\n",
    "irreps_features = o3.Irreps(irreps_features)\n",
    "\n",
    "Extract_new = Extract(hidden_layer_irrep,\n",
    "        [irreps_scalar, irreps_features],\n",
    "        instructions=[(0,), (1, 2, 3, 4, 5)])\n",
    "out2 = Extract_new(out)\n",
    "\n",
    "Extract_new.irreps_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4115a7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([364, 32]), torch.Size([364, 544]), torch.Size([364, 576]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[0].shape, out2[1].shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b6ab7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "in_1 = o3.Irreps('32x0e')\n",
    "in_2 = o3.Irreps('32x0e')\n",
    "\n",
    "ir_out2 = in_1 + in_2\n",
    "\n",
    "scalar_concat = torch.concatenate([latent_vector_out, out2[0]], dim = -1)\n",
    "\n",
    "linear_scalar = o3.Linear(ir_out2, '32x0e')\n",
    "linear_features = o3.Linear(hidden_layer_irrep, hidden_layer_irrep)\n",
    "\n",
    "\n",
    "\n",
    "data2_my['scalar'] = linear_scalar(scalar_concat) + latent_vector_out\n",
    "data2_my['edge_attrs'] = linear_features(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a32df3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e830704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5633, -2.9845,  3.7044,  ...,  2.2098,  2.6116,  2.2809],\n",
       "        [-3.7988, -0.1964,  3.8040,  ..., -3.7400, -1.1233, -1.0725],\n",
       "        [-2.3400,  1.8147,  2.9686,  ..., -3.1784,  1.0734,  1.9833],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "062c277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(0, 32, None),\n",
       " slice(32, 128, None),\n",
       " slice(128, 224, None),\n",
       " slice(224, 384, None),\n",
       " slice(384, 544, None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Extract_new.irreps_outs[1].slices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25e3ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.]), tensor([2.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Extract('1e + 0e + 0e', ['0e', '0e'], [(1,), (2,)])\n",
    "c(torch.tensor([0.0, 0.0, 0.0, 1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcde216c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_layer_irrep), len(irreps_scalar), len(irreps_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30593da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 96, 96, 160, 160)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(el.dim for el in hidden_layer_irrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b431ecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 96, 96, 160, 160)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(el.dim for el in irreps_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f68958ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+32x0o+32x1e+32x1o+32x2e+32x2o"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_irrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "067d58a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(irreps_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d041d704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0o+32x1e+32x1o+32x2e+32x2o"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7382a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "irreps_features.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "857ce025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0o+32x1e+32x1o+32x2e+32x2o"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1b1e51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_attrs\n",
      "edge_attrs\n",
      "edge_embedding\n"
     ]
    }
   ],
   "source": [
    "print(AtomicDataDict.NODE_ATTRS_KEY)\n",
    "print(AtomicDataDict.EDGE_ATTRS_KEY)\n",
    "print(AtomicDataDict.EDGE_EMBEDDING_KEY)\n",
    "#data_my['node_attrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb7d36",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04a0068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "data = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "\n",
    "\n",
    "\n",
    "# edge length embedding\n",
    "torch.manual_seed(32)\n",
    "\n",
    "num_basis = 8\n",
    "r_max = 5\n",
    "\n",
    "\n",
    "data_my = {key: torch.clone(data[key]) for key in data}\n",
    "data_my = AtomicDataDict.with_edge_vectors(data_my, with_lengths=True)\n",
    "\n",
    "edge_length = data_my['edge_lengths']\n",
    "\n",
    "bessel_weights = (torch.linspace(start=1.0, end=num_basis, steps=num_basis) * math.pi)\n",
    "bessel_weights = nn.Parameter(bessel_weights)\n",
    "\n",
    "edge_length_embedding = 2/r_max*torch.sin(bessel_weights * edge_length.unsqueeze(-1) / r_max)/edge_length.unsqueeze(-1)\n",
    "\n",
    "# cutoff\n",
    "factor = 1/r_max\n",
    "p = 6\n",
    "    \n",
    "x = edge_length * factor\n",
    "\n",
    "cutoff = 1.0\n",
    "cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "cutoff *= (x < 1.0)\n",
    "\n",
    "cutoff = cutoff.unsqueeze(-1)\n",
    "\n",
    "data_my['edge_embedding'] = edge_length_embedding * cutoff\n",
    "\n",
    "# types embedding\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "edge_ind = data_my['edge_index']\n",
    "\n",
    "types_embed = one_hot(dataset[0]['atom_types'], num_classes)\n",
    "types_src = types_embed[edge_ind[0]].squeeze(1)\n",
    "types_dst = types_embed[edge_ind[1]].squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# latent vector\n",
    "latent_vector = torch.concatenate([types_src, types_dst, edge_length_embedding], dim = 1)\n",
    "\n",
    "# MLP\n",
    "invariant_layers = 2\n",
    "invariant_neurons = 64\n",
    "out_neurons = 32\n",
    "\n",
    "fc = FullyConnectedNet(\n",
    "    [latent_vector.shape[1]]\n",
    "    + invariant_layers * [invariant_neurons]\n",
    "    + [out_neurons],\n",
    "    torch.nn.functional.silu)\n",
    "\n",
    "latent_vector_out = fc(latent_vector)\n",
    "\n",
    "\n",
    "data_my['scalar'] = latent_vector_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cc52dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnequip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphModuleMixin\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnequip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tp_path_exists\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScalarMLPFunction\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _keys\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_strided\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Contracter, MakeWeightedChannels, Linear\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "import math\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch_runstats.scatter import scatter\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.util.jit import compile_mode\n",
    "\n",
    "from nequip.data import AtomicDataDict\n",
    "from nequip.nn import GraphModuleMixin\n",
    "from nequip.utils.tp_utils import tp_path_exists\n",
    "\n",
    "from ._fc import ScalarMLPFunction\n",
    "from .. import _keys\n",
    "from ._strided import Contracter, MakeWeightedChannels, Linear\n",
    "from .cutoffs import cosine_cutoff, polynomial_cutoff\n",
    "\n",
    "\n",
    "@compile_mode(\"script\")\n",
    "class Allegro_Module(GraphModuleMixin, torch.nn.Module):\n",
    "    # saved params\n",
    "    num_layers: int\n",
    "    field: str\n",
    "    out_field: str\n",
    "    num_types: int\n",
    "    env_embed_mul: int\n",
    "    weight_numel: int\n",
    "    latent_resnet: bool\n",
    "    embed_initial_edge: bool\n",
    "\n",
    "    # internal values\n",
    "    _env_builder_w_index: List[int]\n",
    "    _env_builder_n_irreps: int\n",
    "    _input_pad: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # required params\n",
    "        num_layers: int,\n",
    "        num_types: int,\n",
    "        r_max: float,\n",
    "        avg_num_neighbors: Optional[float] = None,\n",
    "        # cutoffs\n",
    "        r_start_cos_ratio: float = 0.8,\n",
    "        PolynomialCutoff_p: float = 6,\n",
    "        per_layer_cutoffs: Optional[List[float]] = None,\n",
    "        cutoff_type: str = \"polynomial\",\n",
    "        # general hyperparameters:\n",
    "        field: str = AtomicDataDict.EDGE_ATTRS_KEY,\n",
    "        edge_invariant_field: str = AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "        node_invariant_field: str = AtomicDataDict.NODE_ATTRS_KEY,\n",
    "        env_embed_multiplicity: int = 32,\n",
    "        embed_initial_edge: bool = True,\n",
    "        linear_after_env_embed: bool = False,\n",
    "        nonscalars_include_parity: bool = True,\n",
    "        # MLP parameters:\n",
    "        two_body_latent=ScalarMLPFunction,\n",
    "        two_body_latent_kwargs={},\n",
    "        env_embed=ScalarMLPFunction,\n",
    "        env_embed_kwargs={},\n",
    "        latent=ScalarMLPFunction,\n",
    "        latent_kwargs={},\n",
    "        latent_resnet: bool = True,\n",
    "        latent_resnet_update_ratios: Optional[List[float]] = None,\n",
    "        latent_resnet_update_ratios_learnable: bool = False,\n",
    "        latent_out_field: Optional[str] = _keys.EDGE_FEATURES,\n",
    "        # Performance parameters:\n",
    "        pad_to_alignment: int = 1,\n",
    "        sparse_mode: Optional[str] = None,\n",
    "        # Other:\n",
    "        irreps_in=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        SCALAR = o3.Irrep(\"0e\")  # define for convinience\n",
    "\n",
    "        # save parameters\n",
    "        assert (\n",
    "            num_layers >= 1\n",
    "        )  # zero layers is \"two body\", but we don't need to support that fallback case\n",
    "        self.num_layers = num_layers\n",
    "        self.nonscalars_include_parity = nonscalars_include_parity\n",
    "        self.field = field\n",
    "        self.latent_out_field = latent_out_field\n",
    "        self.edge_invariant_field = edge_invariant_field\n",
    "        self.node_invariant_field = node_invariant_field\n",
    "        self.latent_resnet = latent_resnet\n",
    "        self.env_embed_mul = env_embed_multiplicity\n",
    "        self.r_start_cos_ratio = r_start_cos_ratio\n",
    "        self.polynomial_cutoff_p = float(PolynomialCutoff_p)\n",
    "        self.cutoff_type = cutoff_type\n",
    "        assert cutoff_type in (\"cosine\", \"polynomial\")\n",
    "        self.embed_initial_edge = embed_initial_edge\n",
    "        self.avg_num_neighbors = avg_num_neighbors\n",
    "        self.linear_after_env_embed = linear_after_env_embed\n",
    "        self.num_types = num_types\n",
    "\n",
    "        # set up irreps\n",
    "        self._init_irreps(\n",
    "            irreps_in=irreps_in,\n",
    "            required_irreps_in=[\n",
    "                self.field,\n",
    "                self.edge_invariant_field,\n",
    "                self.node_invariant_field,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # for normalization of env embed sums\n",
    "        # one per layer\n",
    "        self.register_buffer(\n",
    "            \"env_sum_normalizations\",\n",
    "            # dividing by sqrt(N)\n",
    "            torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),\n",
    "        )\n",
    "\n",
    "        latent = functools.partial(latent, **latent_kwargs)\n",
    "        env_embed = functools.partial(env_embed, **env_embed_kwargs)\n",
    "\n",
    "        self.latents = torch.nn.ModuleList([])\n",
    "        self.env_embed_mlps = torch.nn.ModuleList([])\n",
    "        self.tps = torch.nn.ModuleList([])\n",
    "        self.linears = torch.nn.ModuleList([])\n",
    "        self.env_linears = torch.nn.ModuleList([])\n",
    "\n",
    "        # Embed to the spharm * it as mul\n",
    "        input_irreps = self.irreps_in[self.field]\n",
    "        # this is not inherant, but no reason to fix right now:\n",
    "        assert all(mul == 1 for mul, ir in input_irreps)\n",
    "        env_embed_irreps = o3.Irreps([(1, ir) for _, ir in input_irreps])\n",
    "        assert (\n",
    "            env_embed_irreps[0].ir == SCALAR\n",
    "        ), \"env_embed_irreps must start with scalars\"\n",
    "        self._input_pad = (\n",
    "            int(math.ceil(env_embed_irreps.dim / pad_to_alignment)) * pad_to_alignment\n",
    "        ) - env_embed_irreps.dim\n",
    "        self.register_buffer(\"_zero\", torch.zeros(1, 1))\n",
    "\n",
    "        # Initially, we have the B(r)Y(\\vec{r})-projection of the edges\n",
    "        # (possibly embedded)\n",
    "        if self.embed_initial_edge:\n",
    "            arg_irreps = env_embed_irreps\n",
    "        else:\n",
    "            arg_irreps = input_irreps\n",
    "\n",
    "        # - begin irreps -\n",
    "        # start to build up the irreps for the iterated TPs\n",
    "        tps_irreps = [arg_irreps]\n",
    "\n",
    "        for layer_idx in range(num_layers):\n",
    "            # Create higher order terms cause there are more TPs coming\n",
    "            if layer_idx == 0:\n",
    "                # Add parity irreps\n",
    "                ir_out = []\n",
    "                for (mul, ir) in env_embed_irreps:\n",
    "                    if self.nonscalars_include_parity:\n",
    "                        # add both parity options\n",
    "                        ir_out.append((1, (ir.l, 1)))\n",
    "                        ir_out.append((1, (ir.l, -1)))\n",
    "                    else:\n",
    "                        # add only the parity option seen in the inputs\n",
    "                        ir_out.append((1, ir))\n",
    "\n",
    "                ir_out = o3.Irreps(ir_out)\n",
    "\n",
    "            if layer_idx == self.num_layers - 1:\n",
    "                # ^ means we're doing the last layer\n",
    "                # No more TPs follow this, so only need scalars\n",
    "                ir_out = o3.Irreps([(1, (0, 1))])\n",
    "\n",
    "            # Prune impossible paths\n",
    "            ir_out = o3.Irreps(\n",
    "                [\n",
    "                    (mul, ir)\n",
    "                    for mul, ir in ir_out\n",
    "                    if tp_path_exists(arg_irreps, env_embed_irreps, ir)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # the argument to the next tensor product is the output of this one\n",
    "            arg_irreps = ir_out\n",
    "            tps_irreps.append(ir_out)\n",
    "        # - end build irreps -\n",
    "\n",
    "        # == Remove unneeded paths ==\n",
    "        out_irreps = tps_irreps[-1]\n",
    "        new_tps_irreps = [out_irreps]\n",
    "        for arg_irreps in reversed(tps_irreps[:-1]):\n",
    "            new_arg_irreps = []\n",
    "            for mul, arg_ir in arg_irreps:\n",
    "                for _, env_ir in env_embed_irreps:\n",
    "                    if any(i in out_irreps for i in arg_ir * env_ir):\n",
    "                        # arg_ir is useful: arg_ir * env_ir has a path to something we want\n",
    "                        new_arg_irreps.append((mul, arg_ir))\n",
    "                        # once its useful once, we keep it no matter what\n",
    "                        break\n",
    "            new_arg_irreps = o3.Irreps(new_arg_irreps)\n",
    "            new_tps_irreps.append(new_arg_irreps)\n",
    "            out_irreps = new_arg_irreps\n",
    "\n",
    "        assert len(new_tps_irreps) == len(tps_irreps)\n",
    "        tps_irreps = list(reversed(new_tps_irreps))\n",
    "        del new_tps_irreps\n",
    "\n",
    "        assert tps_irreps[-1].lmax == 0\n",
    "\n",
    "        tps_irreps_in = tps_irreps[:-1]\n",
    "        tps_irreps_out = tps_irreps[1:]\n",
    "        del tps_irreps\n",
    "\n",
    "        # Environment builder:\n",
    "        self._env_weighter = MakeWeightedChannels(\n",
    "            irreps_in=input_irreps,\n",
    "            multiplicity_out=env_embed_multiplicity,\n",
    "            pad_to_alignment=pad_to_alignment,\n",
    "        )\n",
    "\n",
    "        self._n_scalar_outs = []\n",
    "\n",
    "        # == Build TPs ==\n",
    "        for layer_idx, (arg_irreps, out_irreps) in enumerate(\n",
    "            zip(tps_irreps_in, tps_irreps_out)\n",
    "        ):\n",
    "            # Make the env embed linear\n",
    "            if self.linear_after_env_embed:\n",
    "                self.env_linears.append(\n",
    "                    Linear(\n",
    "                        [(env_embed_multiplicity, ir) for _, ir in env_embed_irreps],\n",
    "                        [(env_embed_multiplicity, ir) for _, ir in env_embed_irreps],\n",
    "                        shared_weights=True,\n",
    "                        internal_weights=True,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.env_linears.append(torch.nn.Identity())\n",
    "            # Make TP\n",
    "            tmp_i_out: int = 0\n",
    "            instr = []\n",
    "            n_scalar_outs: int = 0\n",
    "            full_out_irreps = []\n",
    "            for i_out, (_, ir_out) in enumerate(out_irreps):\n",
    "                for i_1, (_, ir_1) in enumerate(arg_irreps):\n",
    "                    for i_2, (_, ir_2) in enumerate(env_embed_irreps):\n",
    "                        if ir_out in ir_1 * ir_2:\n",
    "                            if ir_out == SCALAR:\n",
    "                                n_scalar_outs += 1\n",
    "                            instr.append((i_1, i_2, tmp_i_out))\n",
    "                            full_out_irreps.append((env_embed_multiplicity, ir_out))\n",
    "                            tmp_i_out += 1\n",
    "            full_out_irreps = o3.Irreps(full_out_irreps)\n",
    "            self._n_scalar_outs.append(n_scalar_outs)\n",
    "            assert all(ir == SCALAR for _, ir in full_out_irreps[:n_scalar_outs])\n",
    "            tp = Contracter(\n",
    "                irreps_in1=o3.Irreps(\n",
    "                    [\n",
    "                        (\n",
    "                            (\n",
    "                                env_embed_multiplicity\n",
    "                                if layer_idx > 0 or self.embed_initial_edge\n",
    "                                else 1\n",
    "                            ),\n",
    "                            ir,\n",
    "                        )\n",
    "                        for _, ir in arg_irreps\n",
    "                    ]\n",
    "                ),\n",
    "                irreps_in2=o3.Irreps(\n",
    "                    [(env_embed_multiplicity, ir) for _, ir in env_embed_irreps]\n",
    "                ),\n",
    "                irreps_out=o3.Irreps(\n",
    "                    [(env_embed_multiplicity, ir) for _, ir in full_out_irreps]\n",
    "                ),\n",
    "                instructions=instr,\n",
    "                # For the first layer, we have the unprocessed edges\n",
    "                # coming in from the input if `not self.embed_initial_edge`.\n",
    "                # These don't match the embedding in mul, so we have\n",
    "                # to use uvv --- since the input edges should be mul\n",
    "                # of one in normal circumstances, this is still plenty fast.\n",
    "                # For this reason it also doesn't increase the number of weights.\n",
    "                connection_mode=(\n",
    "                    \"uuu\" if layer_idx > 0 or self.embed_initial_edge else \"uvv\"\n",
    "                ),\n",
    "                shared_weights=False,\n",
    "                has_weight=False,\n",
    "                pad_to_alignment=pad_to_alignment,\n",
    "                sparse_mode=sparse_mode,\n",
    "            )\n",
    "            self.tps.append(tp)\n",
    "            # we extract the scalars from the first irrep of the tp\n",
    "            assert out_irreps[0].ir == SCALAR\n",
    "\n",
    "            # Make env embed mlp\n",
    "            generate_n_weights = (\n",
    "                self._env_weighter.weight_numel\n",
    "            )  # the weight for the edge embedding\n",
    "            if layer_idx == 0 and self.embed_initial_edge:\n",
    "                # also need weights to embed the edge itself\n",
    "                # this is because the 2 body latent is mixed in with the first layer\n",
    "                # in terms of code\n",
    "                generate_n_weights += self._env_weighter.weight_numel\n",
    "\n",
    "            # the linear acts after the extractor\n",
    "            self.linears.append(\n",
    "                Linear(\n",
    "                    full_out_irreps,\n",
    "                    [(env_embed_multiplicity, ir) for _, ir in out_irreps],\n",
    "                    shared_weights=True,\n",
    "                    internal_weights=True,\n",
    "                    pad_to_alignment=pad_to_alignment,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if layer_idx == 0:\n",
    "                # at the first layer, we have no invariants from previous TPs\n",
    "                self.latents.append(\n",
    "                    two_body_latent(\n",
    "                        mlp_input_dimension=(\n",
    "                            (\n",
    "                                # Node invariants for center and neighbor (chemistry)\n",
    "                                2 * self.irreps_in[self.node_invariant_field].num_irreps\n",
    "                                # Plus edge invariants for the edge (radius).\n",
    "                                + self.irreps_in[self.edge_invariant_field].num_irreps\n",
    "                            )\n",
    "                        ),\n",
    "                        mlp_output_dimension=None,\n",
    "                        **two_body_latent_kwargs,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.latents.append(\n",
    "                    latent(\n",
    "                        mlp_input_dimension=(\n",
    "                            (\n",
    "                                # the embedded latent invariants from the previous layer(s)\n",
    "                                self.latents[-1].out_features\n",
    "                                # and the invariants extracted from the last layer's TP:\n",
    "                                + env_embed_multiplicity * n_scalar_outs\n",
    "                            )\n",
    "                        ),\n",
    "                        mlp_output_dimension=None,\n",
    "                    )\n",
    "                )\n",
    "            # the env embed MLP takes the last latent's output as input\n",
    "            # and outputs enough weights for the env embedder\n",
    "            self.env_embed_mlps.append(\n",
    "                env_embed(\n",
    "                    mlp_input_dimension=self.latents[-1].out_features,\n",
    "                    mlp_output_dimension=generate_n_weights,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # For the final layer, we specialize:\n",
    "        # we don't need to propagate nonscalars, so there is no TP\n",
    "        # thus we only need the latent:\n",
    "        self.final_latent = latent(\n",
    "            mlp_input_dimension=self.latents[-1].out_features\n",
    "            + env_embed_multiplicity * n_scalar_outs,\n",
    "            mlp_output_dimension=None,\n",
    "        )\n",
    "        # - end build modules -\n",
    "\n",
    "        # - layer resnet update weights -\n",
    "        if latent_resnet_update_ratios is None:\n",
    "            # We initialize to zeros, which under the sigmoid() become 0.5\n",
    "            # so 1/2 * layer_1 + 1/4 * layer_2 + ...\n",
    "            # note that the sigmoid of these are the factor _between_ layers\n",
    "            # so the first entry is the ratio for the latent resnet of the first and second layers, etc.\n",
    "            # e.g. if there are 3 layers, there are 2 ratios: l1:l2, l2:l3\n",
    "            latent_resnet_update_params = torch.zeros(self.num_layers)\n",
    "        else:\n",
    "            latent_resnet_update_ratios = torch.as_tensor(\n",
    "                latent_resnet_update_ratios, dtype=torch.get_default_dtype()\n",
    "            )\n",
    "            assert latent_resnet_update_ratios.min() > 0.0\n",
    "            assert latent_resnet_update_ratios.min() < 1.0\n",
    "            latent_resnet_update_params = torch.special.logit(\n",
    "                latent_resnet_update_ratios\n",
    "            )\n",
    "            # The sigmoid is mostly saturated at ±6, keep it in a reasonable range\n",
    "            latent_resnet_update_params.clamp_(-6.0, 6.0)\n",
    "        assert latent_resnet_update_params.shape == (\n",
    "            num_layers,\n",
    "        ), f\"There must be {num_layers} layer resnet update ratios (layer0:layer1, layer1:layer2)\"\n",
    "        if latent_resnet_update_ratios_learnable:\n",
    "            self._latent_resnet_update_params = torch.nn.Parameter(\n",
    "                latent_resnet_update_params\n",
    "            )\n",
    "        else:\n",
    "            self.register_buffer(\n",
    "                \"_latent_resnet_update_params\", latent_resnet_update_params\n",
    "            )\n",
    "\n",
    "        # - Per-layer cutoffs -\n",
    "        if per_layer_cutoffs is None:\n",
    "            per_layer_cutoffs = torch.full((num_layers + 1,), r_max)\n",
    "        self.register_buffer(\"per_layer_cutoffs\", torch.as_tensor(per_layer_cutoffs))\n",
    "        assert torch.all(self.per_layer_cutoffs <= r_max)\n",
    "        assert self.per_layer_cutoffs.shape == (\n",
    "            num_layers + 1,\n",
    "        ), \"Must be one per-layer cutoff for layer 0 and every layer for a total of {num_layers} cutoffs (the first applies to the two body latent, which is 'layer 0')\"\n",
    "        assert (\n",
    "            self.per_layer_cutoffs[1:] <= self.per_layer_cutoffs[:-1]\n",
    "        ).all(), \"Per-layer cutoffs must be equal or decreasing\"\n",
    "        assert (\n",
    "            self.per_layer_cutoffs.min() > 0\n",
    "        ), \"Per-layer cutoffs must be >0. To remove higher layers entirely, lower `num_layers`.\"\n",
    "        self._latent_dim = self.final_latent.out_features\n",
    "        self.register_buffer(\"_zero\", torch.as_tensor(0.0))\n",
    "\n",
    "        self.irreps_out.update(\n",
    "            {\n",
    "                self.latent_out_field: o3.Irreps(\n",
    "                    [(self.final_latent.out_features, (0, 1))]\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:\n",
    "        \"\"\"Evaluate.\n",
    "\n",
    "        :param data: AtomicDataDict.Type\n",
    "        :return: AtomicDataDict.Type\n",
    "        \"\"\"\n",
    "        edge_center = data[AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "        edge_neighbor = data[AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "        edge_attr = data[self.field]\n",
    "        # pad edge_attr\n",
    "        if self._input_pad > 0:\n",
    "            edge_attr = torch.cat(\n",
    "                (\n",
    "                    edge_attr,\n",
    "                    self._zero.expand(len(edge_attr), self._input_pad),\n",
    "                ),\n",
    "                dim=-1,\n",
    "            )\n",
    "\n",
    "        edge_length = data[AtomicDataDict.EDGE_LENGTH_KEY]\n",
    "        num_edges: int = len(edge_attr)\n",
    "        edge_invariants = data[self.edge_invariant_field]\n",
    "        node_invariants = data[self.node_invariant_field]\n",
    "        # pre-declare variables as Tensors for TorchScript\n",
    "        scalars = self._zero\n",
    "        coefficient_old = scalars\n",
    "        coefficient_new = scalars\n",
    "        # Initialize state\n",
    "        latents = torch.zeros(\n",
    "            (num_edges, self._latent_dim),\n",
    "            dtype=edge_attr.dtype,\n",
    "            device=edge_attr.device,\n",
    "        )\n",
    "        active_edges = torch.arange(\n",
    "            num_edges,\n",
    "            device=edge_attr.device,\n",
    "        )\n",
    "\n",
    "        # For the first layer, we use the input invariants:\n",
    "        # The center and neighbor invariants and edge invariants\n",
    "        latent_inputs_to_cat = [\n",
    "            node_invariants[edge_center],\n",
    "            node_invariants[edge_neighbor],\n",
    "            edge_invariants,\n",
    "        ]\n",
    "        # The nonscalar features. Initially, the edge data.\n",
    "        features = edge_attr\n",
    "\n",
    "        layer_index: int = 0\n",
    "        # compute the sigmoids vectorized instead of each loop\n",
    "        layer_update_coefficients = self._latent_resnet_update_params.sigmoid()\n",
    "\n",
    "        # Vectorized precompute per layer cutoffs\n",
    "        if self.cutoff_type == \"cosine\":\n",
    "            cutoff_coeffs_all = cosine_cutoff(\n",
    "                edge_length,\n",
    "                self.per_layer_cutoffs,\n",
    "                r_start_cos_ratio=self.r_start_cos_ratio,\n",
    "            )\n",
    "        elif self.cutoff_type == \"polynomial\":\n",
    "            cutoff_coeffs_all = polynomial_cutoff(\n",
    "                edge_length, self.per_layer_cutoffs, p=self.polynomial_cutoff_p\n",
    "            )\n",
    "        else:\n",
    "            # This branch is unreachable (cutoff type is checked in __init__)\n",
    "            # But TorchScript doesn't know that, so we need to make it explicitly\n",
    "            # impossible to make it past so it doesn't throw\n",
    "            # \"cutoff_coeffs_all is not defined in the false branch\"\n",
    "            assert False, \"Invalid cutoff type\"\n",
    "\n",
    "        # !!!! REMEMBER !!!! update final layer if update the code in main loop!!!\n",
    "        # This goes through layer0, layer1, ..., layer_max-1\n",
    "        for latent, env_embed_mlp, env_linear, tp, linear in zip(\n",
    "            self.latents, self.env_embed_mlps, self.env_linears, self.tps, self.linears\n",
    "        ):\n",
    "            # Determine which edges are still in play\n",
    "            cutoff_coeffs = cutoff_coeffs_all[layer_index]\n",
    "            prev_mask = cutoff_coeffs[active_edges] > 0\n",
    "            active_edges = (cutoff_coeffs > 0).nonzero().squeeze(-1)\n",
    "\n",
    "            # Compute latents\n",
    "            new_latents = latent(torch.cat(latent_inputs_to_cat, dim=-1)[prev_mask])\n",
    "            # Apply cutoff, which propagates through to everything else\n",
    "            new_latents = cutoff_coeffs[active_edges].unsqueeze(-1) * new_latents\n",
    "\n",
    "            if self.latent_resnet and layer_index > 0:\n",
    "                this_layer_update_coeff = layer_update_coefficients[layer_index - 1]\n",
    "                # At init, we assume new and old to be approximately uncorrelated\n",
    "                # Thus their variances add\n",
    "                # we always want the latent space to be normalized to variance = 1.0,\n",
    "                # because it is critical for learnability. Still, we want to preserve\n",
    "                # the _relative_ magnitudes of the current latent and the residual update\n",
    "                # to be controled by `this_layer_update_coeff`\n",
    "                # Solving the simple system for the two coefficients:\n",
    "                #   a^2 + b^2 = 1  (variances add)   &    a * this_layer_update_coeff = b\n",
    "                # gives\n",
    "                #   a = 1 / sqrt(1 + this_layer_update_coeff^2)  &  b = this_layer_update_coeff / sqrt(1 + this_layer_update_coeff^2)\n",
    "                # rsqrt is reciprocal sqrt\n",
    "                coefficient_old = torch.rsqrt(this_layer_update_coeff.square() + 1)\n",
    "                coefficient_new = this_layer_update_coeff * coefficient_old\n",
    "                # Residual update\n",
    "                # Note that it only runs when there are latents to resnet with, so not at the first layer\n",
    "                # index_add adds only to the edges for which we have something to contribute\n",
    "                latents = torch.index_add(\n",
    "                    coefficient_old * latents,\n",
    "                    0,\n",
    "                    active_edges,\n",
    "                    coefficient_new * new_latents,\n",
    "                )\n",
    "            else:\n",
    "                # Normal (non-residual) update\n",
    "                # index_copy replaces, unlike index_add\n",
    "                latents = torch.index_copy(latents, 0, active_edges, new_latents)\n",
    "\n",
    "            # From the latents, compute the weights for active edges:\n",
    "            weights = env_embed_mlp(latents[active_edges])\n",
    "            w_index: int = 0\n",
    "\n",
    "            if self.embed_initial_edge and layer_index == 0:\n",
    "                # embed initial edge\n",
    "                env_w = weights.narrow(-1, w_index, self._env_weighter.weight_numel)\n",
    "                w_index += self._env_weighter.weight_numel\n",
    "                features = self._env_weighter(\n",
    "                    features[prev_mask], env_w\n",
    "                )  # features is edge_attr\n",
    "            else:\n",
    "                # just take the previous features that we still need\n",
    "                features = features[prev_mask]\n",
    "\n",
    "            # Extract weights for the environment builder\n",
    "            env_w = weights.narrow(-1, w_index, self._env_weighter.weight_numel)\n",
    "            w_index += self._env_weighter.weight_numel\n",
    "\n",
    "            # Build the local environments\n",
    "            # This local environment should only be a sum over neighbors\n",
    "            # who are within the cutoff of the _current_ layer\n",
    "            # Those are the active edges, which are the only ones we\n",
    "            # have weights for (env_w) anyway.\n",
    "            # So we mask out the edges in the sum:\n",
    "            local_env_per_edge = scatter(\n",
    "                self._env_weighter(edge_attr[active_edges], env_w),\n",
    "                edge_center[active_edges],\n",
    "                dim=0,\n",
    "            )\n",
    "            if self.env_sum_normalizations.ndim < 2:\n",
    "                # it's a scalar per layer\n",
    "                norm_const = self.env_sum_normalizations[layer_index]\n",
    "            else:\n",
    "                # it's per type\n",
    "                # get shape [N_atom, 1] for broadcasting\n",
    "                norm_const = self.env_sum_normalizations[\n",
    "                    layer_index, data[AtomicDataDict.ATOM_TYPE_KEY]\n",
    "                ].unsqueeze(-1)\n",
    "            local_env_per_edge = local_env_per_edge * norm_const\n",
    "            local_env_per_edge = env_linear(local_env_per_edge)\n",
    "            # Copy to get per-edge\n",
    "            # Large allocation, but no better way to do this:\n",
    "            local_env_per_edge = local_env_per_edge[edge_center[active_edges]]\n",
    "\n",
    "            # Now do the TP\n",
    "            # recursively tp current features with the environment embeddings\n",
    "            features = tp(features, local_env_per_edge)\n",
    "\n",
    "            # Get invariants\n",
    "            # features has shape [z][mul][k]\n",
    "            # we know scalars are first\n",
    "            scalars = features[:, :, : self._n_scalar_outs[layer_index]].reshape(\n",
    "                features.shape[0], -1\n",
    "            )\n",
    "\n",
    "            # do the linear\n",
    "            features = linear(features)\n",
    "\n",
    "            # For layer2+, use the previous latents and scalars\n",
    "            # This makes it deep\n",
    "            latent_inputs_to_cat = [\n",
    "                latents[active_edges],\n",
    "                scalars,\n",
    "            ]\n",
    "\n",
    "            # increment co_unter\n",
    "            layer_index += 1\n",
    "\n",
    "        # - final layer -\n",
    "        # due to TorchScript limitations, we have to\n",
    "        # copy and repeat the code here --- no way to\n",
    "        # escape the final iteration of the loop early\n",
    "        cutoff_coeffs = cutoff_coeffs_all[layer_index]\n",
    "        prev_mask = cutoff_coeffs[active_edges] > 0\n",
    "        active_edges = (cutoff_coeffs > 0).nonzero().squeeze(-1)\n",
    "        new_latents = self.final_latent(\n",
    "            torch.cat(latent_inputs_to_cat, dim=-1)[prev_mask]\n",
    "        )\n",
    "        new_latents = cutoff_coeffs[active_edges].unsqueeze(-1) * new_latents\n",
    "        if self.latent_resnet:\n",
    "            this_layer_update_coeff = layer_update_coefficients[layer_index - 1]\n",
    "            coefficient_old = torch.rsqrt(this_layer_update_coeff.square() + 1)\n",
    "            coefficient_new = this_layer_update_coeff * coefficient_old\n",
    "            latents = torch.index_add(\n",
    "                coefficient_old * latents,\n",
    "                0,\n",
    "                active_edges,\n",
    "                coefficient_new * new_latents,\n",
    "            )\n",
    "        else:\n",
    "            latents = torch.index_copy(latents, 0, active_edges, new_latents)\n",
    "        # - end final layer -\n",
    "\n",
    "        # final latents\n",
    "        data[self.latent_out_field] = latents\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc0c3a",
   "metadata": {},
   "source": [
    "### Edge embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53f2d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "irreps_in = {}\n",
    "\n",
    "data = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "\n",
    "\n",
    "\n",
    "# edge length embedding\n",
    "torch.manual_seed(32)\n",
    "\n",
    "num_basis = 8\n",
    "r_max = 5\n",
    "\n",
    "\n",
    "data_in = {key: torch.clone(data[key]) for key in data}\n",
    "data_in = AtomicDataDict.with_edge_vectors(data_in, with_lengths=True)\n",
    "\n",
    "edge_length = data_my['edge_lengths']\n",
    "\n",
    "bessel_weights = (torch.linspace(start=1.0, end=num_basis, steps=num_basis) * math.pi)\n",
    "bessel_weights = nn.Parameter(bessel_weights)\n",
    "\n",
    "edge_length_embedding = 2/r_max*torch.sin(bessel_weights * edge_length.unsqueeze(-1) / r_max)/edge_length.unsqueeze(-1)\n",
    "\n",
    "# cutoff\n",
    "factor = 1/r_max\n",
    "p = 6\n",
    "    \n",
    "x = edge_length * factor\n",
    "\n",
    "cutoff = 1.0\n",
    "cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "cutoff *= (x < 1.0)\n",
    "\n",
    "cutoff = cutoff.unsqueeze(-1)\n",
    "\n",
    "data_in['edge_embedding'] = edge_length_embedding * cutoff\n",
    "\n",
    "irreps_in['edge_embedding'] = o3.Irreps(f'{num_basis}x0e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "853efb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 8])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in['edge_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2f5e7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8x0e+2x0e"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_in['edge_embedding'] + '2x0e'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dabdca",
   "metadata": {},
   "source": [
    "### Node attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fecd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from nequip.data import AtomicData, AtomicDataDict\n",
    "from torch.nn.functional import one_hot\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "    \n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "# types embedding\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "types_embed = one_hot(data_in['atom_types'], num_classes).squeeze(1)\n",
    "\n",
    "data_in['node_attrs'] = types_embed\n",
    "\n",
    "irreps_in['node_attrs'] = o3.Irreps(f'{num_classes}x0e')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ade01",
   "metadata": {},
   "source": [
    "### Edge attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95f6c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "\n",
    "l_max = 2\n",
    "irreps_edge_sh = o3.Irreps.spherical_harmonics(2)\n",
    "\n",
    "#data_in = {key: torch.clone(data_in[key]) for key in data_my}\n",
    "data_in = AtomicDataDict.with_edge_vectors(data_in, with_lengths=False)\n",
    "\n",
    "\n",
    "harm_gen = o3.SphericalHarmonics(irreps_edge_sh, True, 'component')\n",
    "\n",
    "edge_vec = data_in['edge_vectors']\n",
    "\n",
    "harm_edge = harm_gen(edge_vec)\n",
    "harm_edge.shape\n",
    "\n",
    "\n",
    "data_in['edge_attrs'] = harm_edge\n",
    "\n",
    "irreps_in['edge_attrs'] = irreps_edge_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7be743d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allegro.nn import Allegro_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05698ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Allegro_Module(\n",
       "  (latents): ModuleList(\n",
       "    (0-1): 2 x ScalarMLPFunction(\n",
       "      (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "    )\n",
       "  )\n",
       "  (env_embed_mlps): ModuleList(\n",
       "    (0-1): 2 x ScalarMLPFunction(\n",
       "      (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "    )\n",
       "  )\n",
       "  (tps): ModuleList(\n",
       "    (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "  )\n",
       "  (linears): ModuleList(\n",
       "    (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "  )\n",
       "  (env_linears): ModuleList(\n",
       "    (0-1): 2 x Identity()\n",
       "  )\n",
       "  (_env_weighter): MakeWeightedChannels()\n",
       "  (final_latent): ScalarMLPFunction(\n",
       "    (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self, # required params\n",
    "# num_layers: int, num_types: int,\n",
    "# r_max: float, avg_num_neighbors: Optional[float] = None,\n",
    "# cutoffs\n",
    "# r_start_cos_ratio: float = 0.8, PolynomialCutoff_p: float = 6,\n",
    "# per_layer_cutoffs: Optional[List[float]] = None, cutoff_type: str = \"polynomial\",\n",
    "# general hyperparameters:\n",
    "# field: str = AtomicDataDict.EDGE_ATTRS_KEY,\n",
    "# edge_invariant_field: str = AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "# node_invariant_field: str = AtomicDataDict.NODE_ATTRS_KEY,\n",
    "# env_embed_multiplicity: int = 32,\n",
    "# embed_initial_edge: bool = True,\n",
    "# linear_after_env_embed: bool = False,\n",
    "# nonscalars_include_parity: bool = True,\n",
    "# MLP parameters:\n",
    "# two_body_latent=ScalarMLPFunction,\n",
    "# two_body_latent_kwargs={},\n",
    "# env_embed=ScalarMLPFunction,\n",
    "# env_embed_kwargs={},\n",
    "# latent=ScalarMLPFunction,\n",
    "# latent_kwargs={}, latent_resnet: bool = True,\n",
    "# latent_resnet_update_ratios: Optional[List[float]] = None,\n",
    "# latent_resnet_update_ratios_learnable: bool = False,\n",
    "# latent_out_field: Optional[str] = _keys.EDGE_FEATURES,\n",
    "# Performance parameters:\n",
    "# pad_to_alignment: int = 1,\n",
    "# sparse_mode: Optional[str] = None,\n",
    "# Other:\n",
    "# irreps_in=None,\n",
    "\n",
    "Main_Module = Allegro_Module(r_max = 5,\n",
    "               num_layers = 2,\n",
    "               num_types = 3,\n",
    "               avg_num_neighbors=10., \n",
    "               two_body_latent_kwargs={'mlp_latent_dimensions': [32]},\n",
    "               latent_kwargs={'mlp_latent_dimensions': [32]},\n",
    "               env_embed_kwargs={'mlp_latent_dimensions': [32]},\n",
    "               irreps_in=irreps_in)\n",
    "\n",
    "Main_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf7454aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "Main_Module(data_in)\n",
    "\n",
    "print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d214f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing(GraphModuleMixin, torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, irreps_in = None):\n",
    "        super().__init__()\n",
    "        self._init_irreps(\n",
    "            irreps_in=irreps_in,\n",
    "            irreps_out = {'edge_embedding': '8x0e', 'node_attrs': '3x0e', 'edge_attrs': '1x0e+1x1o+1x2e'}\n",
    "        )\n",
    "        \n",
    "        #self.irreps_in = irreps_in\n",
    "        #self.irreps_out = {'edge_embedding': '8x0e', 'node_attrs': '3x0e', 'edge_attrs': '1x0e+1x1o+1x2e'}\n",
    "    \n",
    "    def forward(self, data_in):\n",
    "        \n",
    "        \n",
    "        \n",
    "        import torch\n",
    "        from torch.nn.functional import one_hot\n",
    "        from nequip.data import AtomicData, AtomicDataDict\n",
    "        from torch.nn.functional import one_hot\n",
    "        from e3nn.nn import FullyConnectedNet\n",
    "\n",
    "        from torch import nn\n",
    "        import math\n",
    "\n",
    "        irreps_in = {}\n",
    "\n",
    "\n",
    "\n",
    "        # edge length embedding\n",
    "        torch.manual_seed(32)\n",
    "\n",
    "        num_basis = 8\n",
    "        r_max = 5\n",
    "\n",
    "\n",
    "        #data_in = {key: torch.clone(data_in[key]) for key in data}\n",
    "        data_in = AtomicDataDict.with_edge_vectors(data_in, with_lengths=True)\n",
    "\n",
    "        edge_length = data_in['edge_lengths']\n",
    "\n",
    "        bessel_weights = (torch.linspace(start=1.0, end=num_basis, steps=num_basis) * math.pi)\n",
    "        bessel_weights = nn.Parameter(bessel_weights)\n",
    "\n",
    "        edge_length_embedding = 2/r_max*torch.sin(bessel_weights * edge_length.unsqueeze(-1) / r_max)/edge_length.unsqueeze(-1)\n",
    "\n",
    "        # cutoff\n",
    "        factor = 1/r_max\n",
    "        p = 6\n",
    "\n",
    "        x = edge_length * factor\n",
    "\n",
    "        cutoff = 1.0\n",
    "        cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "        cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "        cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "        cutoff *= (x < 1.0)\n",
    "\n",
    "        cutoff = cutoff.unsqueeze(-1)\n",
    "\n",
    "        data_in['edge_embedding'] = edge_length_embedding * cutoff\n",
    "\n",
    "        irreps_in['edge_embedding'] = o3.Irreps(f'{num_basis}x0e')\n",
    "        \n",
    "        import torch\n",
    "        from torch.nn.functional import one_hot\n",
    "        from nequip.data import AtomicData, AtomicDataDict\n",
    "        from torch.nn.functional import one_hot\n",
    "        from e3nn.nn import FullyConnectedNet\n",
    "\n",
    "        from torch import nn\n",
    "        import math\n",
    "\n",
    "        # types embedding\n",
    "        num_classes = 3\n",
    "\n",
    "\n",
    "        types_embed = one_hot(data_in['atom_types'], num_classes).squeeze(1)\n",
    "\n",
    "        data_in['node_attrs'] = types_embed\n",
    "\n",
    "        irreps_in['node_attrs'] = o3.Irreps(f'{num_classes}x0e')\n",
    "        \n",
    "        # Edge attrs\n",
    "        from torch import nn\n",
    "        import math\n",
    "\n",
    "\n",
    "        torch.manual_seed(32)\n",
    "\n",
    "\n",
    "        l_max = 2\n",
    "        irreps_edge_sh = o3.Irreps.spherical_harmonics(2)\n",
    "\n",
    "        #data_in = {key: torch.clone(data_in[key]) for key in data_my}\n",
    "        data_in = AtomicDataDict.with_edge_vectors(data_in, with_lengths=False)\n",
    "\n",
    "\n",
    "        harm_gen = o3.SphericalHarmonics(irreps_edge_sh, True, 'component')\n",
    "\n",
    "        edge_vec = data_in['edge_vectors']\n",
    "\n",
    "        harm_edge = harm_gen(edge_vec)\n",
    "        harm_edge.shape\n",
    "\n",
    "\n",
    "        data_in['edge_attrs'] = harm_edge\n",
    "\n",
    "        irreps_in['edge_attrs'] = irreps_edge_sh\n",
    "        \n",
    "        return data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52c03ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing_module_my = Preprocessing()\n",
    "\n",
    "data = AtomicData.to_AtomicDataDict(dataset[0])\n",
    "\n",
    "#Main_Module_my(Preprocessing_module_my(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6adcdf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@compile_mode(\"script\")\n",
    "class Allegro_Module_my(GraphModuleMixin, torch.nn.Module):\n",
    "    # saved params\n",
    "    num_layers: int\n",
    "    field: str\n",
    "    out_field: str\n",
    "    num_types: int\n",
    "    env_embed_mul: int\n",
    "    weight_numel: int\n",
    "    latent_resnet: bool\n",
    "    embed_initial_edge: bool\n",
    "\n",
    "    # internal values\n",
    "    _env_builder_w_index: List[int]\n",
    "    _env_builder_n_irreps: int\n",
    "    _input_pad: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # required params\n",
    "        num_layers: int,\n",
    "        num_types: int,\n",
    "        r_max: float,\n",
    "        avg_num_neighbors: Optional[float] = None,\n",
    "        # cutoffs\n",
    "        r_start_cos_ratio: float = 0.8,\n",
    "        PolynomialCutoff_p: float = 6,\n",
    "        per_layer_cutoffs: Optional[List[float]] = None,\n",
    "        cutoff_type: str = \"polynomial\",\n",
    "        # general hyperparameters:\n",
    "        field: str = AtomicDataDict.EDGE_ATTRS_KEY,\n",
    "        edge_invariant_field: str = AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "        node_invariant_field: str = AtomicDataDict.NODE_ATTRS_KEY,\n",
    "        env_embed_multiplicity: int = 32,\n",
    "        embed_initial_edge: bool = True,\n",
    "        linear_after_env_embed: bool = False,\n",
    "        nonscalars_include_parity: bool = True,\n",
    "        # MLP parameters:\n",
    "        #two_body_latent=ScalarMLPFunction,\n",
    "        #two_body_latent_kwargs={},\n",
    "        #env_embed=ScalarMLPFunction,\n",
    "        #env_embed_kwargs={},\n",
    "        #latent=ScalarMLPFunction,\n",
    "        #latent_kwargs={},\n",
    "        latent_resnet: bool = True,\n",
    "        #latent_resnet_update_ratios: Optional[List[float]] = None,\n",
    "        #latent_resnet_update_ratios_learnable: bool = False,\n",
    "        latent_out_field: Optional[str] = 'edge_features',\n",
    "        # Performance parameters:\n",
    "        pad_to_alignment: int = 1,\n",
    "        sparse_mode: Optional[str] = None,\n",
    "        # Other:\n",
    "        irreps_in=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        SCALAR = o3.Irrep(\"0e\")  # define for convinience\n",
    "\n",
    "        # save parameters\n",
    "        assert (\n",
    "            num_layers >= 1\n",
    "        )  # zero layers is \"two body\", but we don't need to support that fallback case\n",
    "        self.num_layers = num_layers\n",
    "        self.nonscalars_include_parity = nonscalars_include_parity\n",
    "        self.field = field\n",
    "        self.latent_out_field = latent_out_field\n",
    "        self.edge_invariant_field = edge_invariant_field\n",
    "        self.node_invariant_field = node_invariant_field\n",
    "        self.latent_resnet = latent_resnet\n",
    "        self.env_embed_mul = env_embed_multiplicity\n",
    "        self.r_start_cos_ratio = r_start_cos_ratio\n",
    "        self.polynomial_cutoff_p = float(PolynomialCutoff_p)\n",
    "        self.cutoff_type = cutoff_type\n",
    "        assert cutoff_type in (\"cosine\", \"polynomial\")\n",
    "        self.embed_initial_edge = embed_initial_edge\n",
    "        self.avg_num_neighbors = avg_num_neighbors\n",
    "        self.linear_after_env_embed = linear_after_env_embed\n",
    "        self.num_types = num_types\n",
    "\n",
    "        # set up irreps\n",
    "        self._init_irreps(\n",
    "            irreps_in=irreps_in,\n",
    "            required_irreps_in=[\n",
    "                self.field,\n",
    "                self.edge_invariant_field,\n",
    "                self.node_invariant_field,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # for normalization of env embed sums\n",
    "        # one per layer\n",
    "        self.register_buffer(\n",
    "            \"env_sum_normalizations\",\n",
    "            # dividing by sqrt(N)\n",
    "            torch.as_tensor([avg_num_neighbors] * num_layers).rsqrt(),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.latents = torch.nn.ModuleList([])\n",
    "        self.env_embed_mlps = torch.nn.ModuleList([])\n",
    "        self.tps = torch.nn.ModuleList([])\n",
    "        self.linears = torch.nn.ModuleList([])\n",
    "        self.env_linears = torch.nn.ModuleList([])\n",
    "\n",
    "        # Embed to the spharm * it as mul\n",
    "        input_irreps = self.irreps_in[self.field]\n",
    "        # this is not inherant, but no reason to fix right now:\n",
    "        \n",
    "        irrep_hidden = o3.Irreps('32x0e + 32x0o + 32x1e + 32x1o + 32x2e + 32x2e')\n",
    "        irrep_hidden_last = o3.Irreps('32x0e')\n",
    "        \n",
    "        n_basis = 8\n",
    "        \n",
    "        \n",
    "        # First layer\n",
    "        self.latents.append(o3.Linear(o3.Irreps(f'{n_basis + 2 * num_types}x0e'),\n",
    "                                               '32x0e'))\n",
    "        \n",
    "        \n",
    "        self.env_embed_mlps.append(o3.Linear(self.latents[-1].irreps_out, self.latents[-1].irreps_out))\n",
    "        \n",
    "        self.env_linears.append(FullyConnectedTensorProduct(\n",
    "            self.env_embed_mlps[-1].irreps_out,\n",
    "            irreps_in['edge_attrs'],\n",
    "            o3.Irreps([(self.env_embed_mlps[-1].irreps_out[0][0], el[1]) for el in irreps_in['edge_attrs']])\n",
    "        ))\n",
    "        \n",
    "        self.tps.append(FullyConnectedTensorProduct(\n",
    "            irreps_in['edge_attrs'],\n",
    "            self.env_linears[-1].irreps_out,\n",
    "            irrep_hidden\n",
    "        ))\n",
    "        \n",
    "        self.linears.append(o3.Linear(self.tps[-1].irreps_out, self.tps[-1].irreps_out))\n",
    "        \n",
    "        # Second and later layers\n",
    "        for i in range(num_layers - 1):\n",
    "            self.latents.append(o3.Linear('64x0e', '32x0e'))\n",
    "            self.env_embed_mlps.append(o3.Linear(self.latents[-1].irreps_out, self.latents[-1].irreps_out))\n",
    "            \n",
    "            self.env_linears.append(FullyConnectedTensorProduct(\n",
    "                self.env_embed_mlps[-1].irreps_out,\n",
    "                irreps_in['edge_attrs'],\n",
    "                o3.Irreps([(self.env_embed_mlps[-1].irreps_out[0][0], el[1]) for el in irreps_in['edge_attrs']])\n",
    "            ))\n",
    "            \n",
    "            if i != num_layers - 1:\n",
    "                self.tps.append(FullyConnectedTensorProduct(\n",
    "                    irrep_hidden,\n",
    "                    self.env_linears[-1].irreps_out,\n",
    "                    irrep_hidden\n",
    "                ))\n",
    "            # Handling last layer other way\n",
    "            else:\n",
    "                self.tps.append(FullyConnectedTensorProduct(\n",
    "                    irrep_hidden,\n",
    "                    self.env_linears[-1].irreps_out,\n",
    "                    irrep_hidden_last\n",
    "                ))\n",
    "                \n",
    "            self.linears.append(o3.Linear(self.tps[-1].irreps_out, self.tps[-1].irreps_out))\n",
    "            \n",
    "        \n",
    "        self.final_latent = o3.Linear('64x0e', '32x0e')\n",
    "        self.irreps_out['edge_features'] = o3.Irreps('32x0e')\n",
    "        \n",
    "        \n",
    "    def forward(self, data: AtomicDataDict.Type) -> AtomicDataDict.Type:\n",
    "        \n",
    "        \"\"\"Evaluate.\n",
    "\n",
    "        :param data: AtomicDataDict.Type\n",
    "        :return: AtomicDataDict.Type\n",
    "        \"\"\"\n",
    "        data['forces'] = torch.zeros_like(data['pos'])\n",
    "        \n",
    "        edge_center = data[AtomicDataDict.EDGE_INDEX_KEY][0]\n",
    "        edge_neighbor = data[AtomicDataDict.EDGE_INDEX_KEY][1]\n",
    "\n",
    "        edge_attr = data[self.field]\n",
    "        # pad edge_attr\n",
    "        #if self._input_pad > 0:\n",
    "        #    edge_attr = torch.cat(\n",
    "        #        (\n",
    "        #           edge_attr,\n",
    "        #            self._zero.expand(len(edge_attr), self._input_pad),\n",
    "        #        ),\n",
    "        #        dim=-1,\n",
    "        #    )\n",
    "        # The nonscalar features. Initially, the edge data.\n",
    "        features = edge_attr\n",
    "        \n",
    "        \n",
    "        edge_length = data[AtomicDataDict.EDGE_LENGTH_KEY]\n",
    "        num_edges: int = len(edge_attr)\n",
    "        edge_invariants = data[self.edge_invariant_field]\n",
    "        node_invariants = data[self.node_invariant_field]\n",
    "\n",
    "        \n",
    "        # For the first layer, we use the input invariants:\n",
    "        # The center and neighbor invariants and edge invariants\n",
    "        latent_inputs_to_cat = [\n",
    "            node_invariants[edge_center],\n",
    "            node_invariants[edge_neighbor],\n",
    "            edge_invariants,\n",
    "        ]\n",
    "        \n",
    "        # cutoff\n",
    "        r_max = 5\n",
    "        \n",
    "        factor = 1/r_max\n",
    "        p = 6\n",
    "\n",
    "        x = edge_length * factor\n",
    "\n",
    "        cutoff = 1.0\n",
    "        cutoff = cutoff - (((p + 1.0) * (p + 2.0) / 2.0) * torch.pow(x, p))\n",
    "        cutoff = cutoff + (p * (p + 2.0) * torch.pow(x, p + 1.0))\n",
    "        cutoff = cutoff - ((p * (p + 1.0) / 2) * torch.pow(x, p + 2.0))\n",
    "        cutoff *= (x < 1.0)\n",
    "\n",
    "        cutoff_coeffs = cutoff\n",
    "        \n",
    "        layer_index = 0\n",
    "        # !!!! REMEMBER !!!! update final layer if update the code in main loop!!!\n",
    "        # This goes through layer0, layer1, ..., layer_max-1\n",
    "        for latent, env_embed_mlp, env_linear, tp, linear in zip(\n",
    "            self.latents, self.env_embed_mlps, self.env_linears, self.tps, self.linears\n",
    "        ):\n",
    "            # Determine which edges are still in play\n",
    "            new_latents = latent(torch.cat(latent_inputs_to_cat, dim=-1))\n",
    "            # Apply cutoff, which propagates through to everything else\n",
    "            new_latents = cutoff_coeffs.unsqueeze(-1) * new_latents\n",
    "\n",
    "            if self.latent_resnet and layer_index > 0:\n",
    "                # Residual update\n",
    "                latents += new_latents\n",
    "            else:\n",
    "                latents = new_latents\n",
    "                \n",
    "            # From the latents, compute the weights for active edges:\n",
    "            weights = env_embed_mlp(latents)\n",
    "            w_index: int = 0\n",
    "\n",
    "            # Produce right array of features with channels\n",
    "            local_env_per_edge = env_linear(weights, edge_attr)\n",
    "            \n",
    "            # Sum over the env\n",
    "            local_env_per_edge = scatter(local_env_per_edge[edge_neighbor], \n",
    "                                           edge_center, dim=0, dim_size=len(edge_center))\n",
    "            \n",
    "            # Now do the TP\n",
    "            # recursively tp current features with the environment embeddings\n",
    "            features = tp(features, local_env_per_edge)\n",
    "\n",
    "            \n",
    "            print(features.shape, local_env_per_edge.shape)\n",
    "            # Get invariants\n",
    "            # features has shape [z][mul][k]\n",
    "            # we know scalars are first\n",
    "            scalars = features[:, :32].reshape(\n",
    "                features.shape[0], 32)\n",
    "\n",
    "            # do the linear\n",
    "            features = linear(features)\n",
    "\n",
    "            # For layer2+, use the previous latents and scalars\n",
    "            # This makes it deep\n",
    "            latent_inputs_to_cat = [\n",
    "                latents,\n",
    "                scalars,\n",
    "            ]\n",
    "\n",
    "            # increment counter\n",
    "            layer_index += 1\n",
    "\n",
    "        # - final layer -\n",
    "        \n",
    "        new_latents = self.final_latent(\n",
    "            torch.cat(latent_inputs_to_cat, dim=-1)\n",
    "        )\n",
    "        new_latents = cutoff_coeffs.unsqueeze(-1) * new_latents\n",
    "        \n",
    "        latents += new_latents\n",
    "        # - end final layer -\n",
    "\n",
    "        # final latents\n",
    "        data['edge_features'] = latents\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2ee493b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_embedding': 8x0e, 'node_attrs': 3x0e, 'edge_attrs': 1x0e+1x1o+1x2e}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreps_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "741d47ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Allegro_Module_my(\n",
       "  (latents): ModuleList(\n",
       "    (0): Linear(14x0e -> 32x0e | 448 weights)\n",
       "    (1-2): 2 x Linear(64x0e -> 32x0e | 2048 weights)\n",
       "  )\n",
       "  (env_embed_mlps): ModuleList(\n",
       "    (0-2): 3 x Linear(32x0e -> 32x0e | 1024 weights)\n",
       "  )\n",
       "  (tps): ModuleList(\n",
       "    (0): FullyConnectedTensorProduct(1x0e+1x1o+1x2e x 32x0e+32x1o+32x2e -> 32x0e+32x0o+32x1e+32x1o+64x2e | 17408 paths | 17408 weights)\n",
       "    (1-2): 2 x FullyConnectedTensorProduct(32x0e+32x0o+32x1e+32x1o+64x2e x 32x0e+32x1o+32x2e -> 32x0e+32x0o+32x1e+32x1o+64x2e | 1048576 paths | 1048576 weights)\n",
       "  )\n",
       "  (linears): ModuleList(\n",
       "    (0-2): 3 x Linear(32x0e+32x0o+32x1e+32x1o+32x2e+32x2e -> 32x0e+32x0o+32x1e+32x1o+32x2e+32x2e | 8192 weights)\n",
       "  )\n",
       "  (env_linears): ModuleList(\n",
       "    (0-2): 3 x FullyConnectedTensorProduct(32x0e x 1x0e+1x1o+1x2e -> 32x0e+32x1o+32x2e | 3072 paths | 3072 weights)\n",
       "  )\n",
       "  (final_latent): Linear(64x0e -> 32x0e | 2048 weights)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Module_my = Allegro_Module_my(r_max = 5,\n",
    "               num_layers = 3,\n",
    "               num_types = 3,\n",
    "               avg_num_neighbors=10., \n",
    "               irreps_in=irreps_in)\n",
    "\n",
    "Main_Module_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ee12401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([364, 576]) torch.Size([364, 288])\n",
      "torch.Size([364, 576]) torch.Size([364, 288])\n",
      "torch.Size([364, 576]) torch.Size([364, 288])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([364, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Module_my(data_in)['edge_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "458183ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32x0e+32x1o+32x2e"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = o3.Irreps('32x0e') \n",
    "b = o3.Irreps('1x0e + 1x1o + 1x2e')\n",
    "\n",
    "\n",
    "o3.Irreps([(a[0][0], el[1]) for el in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97015f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModel(\n",
       "  (model): RescaleOutput(\n",
       "    (model): GradientOutput(\n",
       "      (func): SequentialGraphNetwork(\n",
       "        (one_hot): OneHotAtomEncoding()\n",
       "        (radial_basis): RadialBasisEdgeEncoding(\n",
       "          (basis): NormalizedBasis(\n",
       "            (basis): BesselBasis()\n",
       "          )\n",
       "          (cutoff): PolynomialCutoff()\n",
       "        )\n",
       "        (spharm): SphericalHarmonicEdgeAttrs(\n",
       "          (sh): SphericalHarmonics()\n",
       "        )\n",
       "        (allegro): Allegro_Module(\n",
       "          (latents): ModuleList(\n",
       "            (0-1): 2 x ScalarMLPFunction(\n",
       "              (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "            )\n",
       "          )\n",
       "          (env_embed_mlps): ModuleList(\n",
       "            (0-1): 2 x ScalarMLPFunction(\n",
       "              (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "            )\n",
       "          )\n",
       "          (tps): ModuleList(\n",
       "            (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "          (linears): ModuleList(\n",
       "            (0-1): 2 x RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "          (env_linears): ModuleList(\n",
       "            (0-1): 2 x Identity()\n",
       "          )\n",
       "          (_env_weighter): MakeWeightedChannels()\n",
       "          (final_latent): ScalarMLPFunction(\n",
       "            (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "        )\n",
       "        (edge_eng): ScalarMLP(\n",
       "          (_module): ScalarMLPFunction(\n",
       "            (_forward): RecursiveScriptModule(original_name=GraphModule)\n",
       "          )\n",
       "        )\n",
       "        (edge_eng_sum): EdgewiseEnergySum()\n",
       "        (per_species_rescale): PerSpeciesScaleShift()\n",
       "        (total_energy_sum): AtomwiseReduce()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ee91fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('edge_features', 'edge_energy')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allegro._keys import EDGE_FEATURES, EDGE_ENERGY\n",
    "\n",
    "EDGE_FEATURES, EDGE_ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50264df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2641e+01,  8.9420e+01,  6.3238e+01,  ..., -6.3859e+01,\n",
       "         -6.2250e+01, -8.4234e+01],\n",
       "        [-1.2339e+02, -3.6850e+01,  2.3579e+02,  ..., -5.7171e-01,\n",
       "          3.2150e+02, -1.3309e+02],\n",
       "        [ 9.0483e+01,  1.6500e+02,  2.3105e+02,  ...,  2.1488e+01,\n",
       "          1.2643e+01, -3.3773e+02],\n",
       "        ...,\n",
       "        [ 6.5446e-01, -3.7539e-01, -2.8281e-01,  ...,  1.0702e+00,\n",
       "         -7.7501e-01, -4.9844e-01],\n",
       "        [ 4.7118e-01,  1.9133e-01, -2.1939e-01,  ..., -1.0747e-01,\n",
       "         -3.2623e-02, -5.4308e-01],\n",
       "        [ 4.7718e-01, -3.1153e-01, -2.1182e-01,  ...,  9.2136e-01,\n",
       "         -8.8922e-01, -4.1402e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in[EDGE_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89a83cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instantiate Preprocessing\n",
      "...Preprocessing_param = dict(\n",
      "...   optional_args = {},\n",
      "...   positional_args = {'irreps_in': None})\n",
      "instantiate Allegro_Module_my\n",
      "   optional_args :                                               r_max\n",
      "   optional_args :                                          num_layers\n",
      "   optional_args :                                   avg_num_neighbors\n",
      "   optional_args :                                           num_types\n",
      "...Allegro_Module_my_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 10.0, 'r_start_cos_ratio': 0.8, 'PolynomialCutoff_p': 6, 'per_layer_cutoffs': None, 'cutoff_type': 'polynomial', 'field': 'edge_attrs', 'edge_invariant_field': 'edge_embedding', 'node_invariant_field': 'node_attrs', 'env_embed_multiplicity': 32, 'embed_initial_edge': True, 'linear_after_env_embed': False, 'nonscalars_include_parity': True, 'latent_resnet': True, 'latent_out_field': 'edge_features', 'pad_to_alignment': 1, 'sparse_mode': None, 'r_max': 5, 'num_layers': 3, 'num_types': 3},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'edge_embedding': 8x0e, 'node_attrs': 3x0e, 'edge_attrs': 1x0e+1x1o+1x2e}})\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "instantiate ScalarMLP\n",
      "   optional_args :                                mlp_output_dimension\n",
      "   optional_args :                               mlp_latent_dimensions\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                               field\n",
      "...ScalarMLP_param = dict(\n",
      "...   optional_args = {'mlp_nonlinearity': 'silu', 'mlp_initialization': 'uniform', 'mlp_dropout_p': 0.0, 'mlp_batchnorm': False, 'field': 'edge_features', 'out_field': 'edge_energy', 'mlp_output_dimension': 1, 'mlp_latent_dimensions': [32]},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'edge_embedding': 8x0e, 'node_attrs': 3x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 32x0e}})\n",
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "instantiate EdgewiseEnergySum\n",
      "   optional_args :                                   avg_num_neighbors\n",
      "   optional_args :                                           num_types\n",
      "...EdgewiseEnergySum_param = dict(\n",
      "...   optional_args = {'avg_num_neighbors': 10.0, 'normalize_edge_energy_sum': True, 'per_edge_species_scale': False, 'num_types': 3.0},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'edge_embedding': 8x0e, 'node_attrs': 3x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 32x0e, 'edge_energy': 1x0e}})\n",
      "instantiate AtomwiseReduce\n",
      "   optional_args :                                              reduce\n",
      "   optional_args :                                           out_field\n",
      "   optional_args :                                               field\n",
      "...AtomwiseReduce_param = dict(\n",
      "...   optional_args = {'out_field': 'total_energy', 'reduce': 'sum', 'avg_num_atoms': None, 'field': 'atomic_energy'},\n",
      "...   positional_args = {'irreps_in': {'pos': 1x1o, 'edge_index': None, 'edge_embedding': 8x0e, 'node_attrs': 3x0e, 'edge_attrs': 1x0e+1x1o+1x2e, 'edge_features': 32x0e, 'edge_energy': 1x0e, 'atomic_energy': 1x0e}})\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "from e3nn import o3\n",
    "\n",
    "from nequip.data import AtomicDataDict, AtomicDataset\n",
    "\n",
    "from nequip.nn import SequentialGraphNetwork, AtomwiseReduce\n",
    "from nequip.nn.radial_basis import BesselBasis\n",
    "\n",
    "from nequip.nn.embedding import (\n",
    "    OneHotAtomEncoding,\n",
    "    SphericalHarmonicEdgeAttrs,\n",
    "    RadialBasisEdgeEncoding,\n",
    ")\n",
    "\n",
    "from allegro.nn import (\n",
    "    NormalizedBasis,\n",
    "    EdgewiseEnergySum,\n",
    "    Allegro_Module,\n",
    "    ScalarMLP,\n",
    ")\n",
    "from allegro._keys import EDGE_FEATURES, EDGE_ENERGY\n",
    "\n",
    "from nequip.model import builder_utils\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "layers = {\n",
    "        # -- Encode --\n",
    "        # Get various edge invariants\n",
    "        \"one_hot\": OneHotAtomEncoding,\n",
    "        \"radial_basis\": (\n",
    "            RadialBasisEdgeEncoding,\n",
    "            dict(\n",
    "                basis=(\n",
    "                    NormalizedBasis\n",
    "                    if config.get(\"normalize_basis\", True)\n",
    "                    else BesselBasis\n",
    "                ),\n",
    "                out_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "            ),\n",
    "        ),\n",
    "        # Get edge nonscalars\n",
    "        \"spharm\": SphericalHarmonicEdgeAttrs,\n",
    "        # The core allegro model:\n",
    "        \"allegro\": (\n",
    "            Allegro_Module,\n",
    "            dict(\n",
    "                field=AtomicDataDict.EDGE_ATTRS_KEY,  # initial input is the edge SH\n",
    "                edge_invariant_field=AtomicDataDict.EDGE_EMBEDDING_KEY,\n",
    "                node_invariant_field=AtomicDataDict.NODE_ATTRS_KEY,\n",
    "            ),\n",
    "        ),\n",
    "        \"edge_eng\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, out_field=EDGE_ENERGY, mlp_output_dimension=1),\n",
    "        ),\n",
    "        # Sum edgewise energies -> per-atom energies:\n",
    "        \"edge_eng_sum\": EdgewiseEnergySum,\n",
    "        # Sum system energy:\n",
    "        \"total_energy_sum\": (\n",
    "            AtomwiseReduce,\n",
    "            dict(\n",
    "                reduce=\"sum\",\n",
    "                field=AtomicDataDict.PER_ATOM_ENERGY_KEY,\n",
    "                out_field=AtomicDataDict.TOTAL_ENERGY_KEY,\n",
    "            ),\n",
    "        ),\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "layers = {\n",
    "    \"Preprocessing\": (Preprocessing,\n",
    "    dict()),\n",
    "    \"Main_Allegro\": (Allegro_Module_my,\n",
    "    dict(r_max = 5,\n",
    "               num_layers = 3,\n",
    "               num_types = 3,\n",
    "               avg_num_neighbors=10.\n",
    "        )),\n",
    "    \"edge_eng\": (\n",
    "            ScalarMLP,\n",
    "            dict(field=EDGE_FEATURES, \n",
    "                 out_field=EDGE_ENERGY, \n",
    "                 mlp_output_dimension=1,\n",
    "                 mlp_latent_dimensions= [32]),\n",
    "        ),\n",
    "        # Sum edgewise energies -> per-atom energies:\n",
    "        \"edge_eng_sum\": (EdgewiseEnergySum,\n",
    "            dict(avg_num_neighbors = 10.,\n",
    "                 num_types = 3.\n",
    "                ),\n",
    "                        ),\n",
    "        # Sum system energy:\n",
    "        \"total_energy_sum\": (\n",
    "            AtomwiseReduce,\n",
    "            dict(\n",
    "                reduce=\"sum\",\n",
    "                field=AtomicDataDict.PER_ATOM_ENERGY_KEY,\n",
    "                out_field=AtomicDataDict.TOTAL_ENERGY_KEY,\n",
    "            ),\n",
    "        ),\n",
    "}\n",
    "\n",
    "\n",
    "model_my = SequentialGraphNetwork({'Preprocessing': Preprocessing_module_my,\n",
    "                                   'Main_Allegro': Main_Module_my}) \n",
    "\n",
    "\n",
    "model_my_from_param = SequentialGraphNetwork.from_parameters(shared_params={},\n",
    "                                                             layers = layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6aa812d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([364, 576]) torch.Size([364, 288])\n",
      "torch.Size([364, 576]) torch.Size([364, 288])\n",
      "torch.Size([364, 576]) torch.Size([364, 288])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_my_from_param(data_in)['forces'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98727fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_energy'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AtomicDataDict.TOTAL_ENERGY_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "722cf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nequip.nn import GraphModel, GradientOutput\n",
    "\n",
    "\n",
    "trainer.model = GraphModel(GradientOutput(model_my_from_param,\n",
    "                                          of = 'total_energy',\n",
    "                                          wrt = 'pos',\n",
    "                                          out_field='forces'))\n",
    "\n",
    "model_my_final = GraphModel(GradientOutput(model_my_from_param,\n",
    "                                          of = 'total_energy',\n",
    "                                          wrt = 'pos',\n",
    "                                          out_field='forces')).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e55be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for el in dataset:\n",
    "#    el['forces'] = torch.zeros_like(el['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e38ad3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].cell.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e78a3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_dataset(dataset, validation_dataset)\n",
    "\n",
    "\n",
    "trainer.model = model_my_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ae0bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "! Starting training ...\n",
      "instantiate Metrics\n",
      "...Metrics_param = dict(\n",
      "...   optional_args = {},\n",
      "...   positional_args = {'components': [('forces', 'mae', {'PerSpecies': False}), ('forces', 'rmse', {'PerSpecies': False}), ('total_energy', 'mae', {'PerSpecies': False}), ('total_energy', 'rmse', {'PerSpecies': False})]})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "instantiate L1Loss\n",
      "...L1Loss_param = dict(\n",
      "...   optional_args = {'size_average': None, 'reduce': None},\n",
      "...   positional_args = {'reduction': 'none'})\n",
      "EarlyStopping: 4 / 100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:784\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_init_callback()\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_cond:\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_of_epoch_save()\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:919\u001b[0m, in \u001b[0;36mTrainer.epoch_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mibatch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVALIDATION\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_of_batch_log(batch_type\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_of_batch_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/train/trainer.py:814\u001b[0m, in \u001b[0;36mTrainer.batch_step\u001b[0;34m(self, data, validation)\u001b[0m\n\u001b[1;32m    810\u001b[0m data_for_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39munscale(data, force_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# Run model\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# We make a shallow copy of the input dict in case the model modifies it\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_for_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# If we're in evaluation mode (i.e. validation), then\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# data_for_loss's target prop is unnormalized, and out's has been rescaled to be in the same units\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# If we're in training, data_for_loss's target prop has been normalized, and out's hasn't been touched, so they're both in normalized units\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# Note that either way all normalization was handled internally by GraphModel via RescaleOutput\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validation:\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# Actually do an optimization step, since we're training:\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/nn/_graph_model.py:112\u001b[0m, in \u001b[0;36mGraphModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    110\u001b[0m         new_data[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# run the model\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/nn/_grad_output.py:85\u001b[0m, in \u001b[0;36mGradientOutput.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     83\u001b[0m     wrt_tensors\u001b[38;5;241m.\u001b[39mappend(data[k])\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# run func\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Get grads\u001b[39;00m\n\u001b[1;32m     87\u001b[0m grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# TODO:\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# This makes sense for scalar batch-level or batch-wise outputs, specifically because d(sum(batches))/d wrt = sum(d batch / d wrt) = d my_batch / d wrt\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,  \u001b[38;5;66;03m# needed to allow gradients of this output during training\u001b[39;00m\n\u001b[1;32m     95\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/nequip/nn/_graph_mixin.py:366\u001b[0m, in \u001b[0;36mSequentialGraphNetwork.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: AtomicDataDict\u001b[38;5;241m.\u001b[39mType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AtomicDataDict\u001b[38;5;241m.\u001b[39mType:\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 45\u001b[0m, in \u001b[0;36mPreprocessing.forward\u001b[0;34m(self, data_in)\u001b[0m\n\u001b[1;32m     42\u001b[0m bessel_weights \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mlinspace(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, end\u001b[38;5;241m=\u001b[39mnum_basis, steps\u001b[38;5;241m=\u001b[39mnum_basis) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)\n\u001b[1;32m     43\u001b[0m bessel_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(bessel_weights)\n\u001b[0;32m---> 45\u001b[0m edge_length_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mr_max\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msin(\u001b[43mbessel_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_length\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m r_max)\u001b[38;5;241m/\u001b[39medge_length\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# cutoff\u001b[39;00m\n\u001b[1;32m     48\u001b[0m factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mr_max\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my_final(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = model_my_from_param(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['forces'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functools partial defines function with some of the arguments already assigned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
